"""
Reconocedor de voz con Whisper - Transcribe cuando dejas de hablar
"""
import whisper
import sounddevice as sd
import numpy as np
from threading import Thread
from queue import Queue
import torch
import time

class SpeechRecognizer:
    def __init__(self, model_size="base"):
        """
        Inicializa el reconocedor con Whisper
        model_size: 'tiny', 'base', 'small', 'medium', 'large'
        """
        print("ğŸ¤ Cargando modelo Whisper...")
        
        # Cargar modelo Whisper
        self.model = whisper.load_model(model_size)
        
        # ConfiguraciÃ³n de audio
        self.sample_rate = 16000
        self.channels = 1
        
        # ConfiguraciÃ³n de detecciÃ³n de voz
        self.silence_threshold = 0.01  # Umbral de energÃ­a para considerar silencio
        self.silence_duration = 1.5    # Segundos de silencio para considerar que terminaste de hablar
        self.min_audio_length = 0.5    # MÃ­nimo de audio en segundos para procesar
        
        # Colas y estado
        self.audio_queue = Queue()
        self.text_queue = Queue()
        self.is_listening = False
        self.audio_buffer = []
        self.is_speaking = False
        self.last_sound_time = None
        
        # Detectar si hay GPU disponible
        self.device = "cuda" if torch.cuda.is_available() else "cpu"
        print(f"âœ… Modelo '{model_size}' cargado en {self.device}")
        print("ğŸ¤ SpeechRecognizer inicializado")
    
    def reset_session(self):
        """
        Limpia completamente el historial de texto y audio
        Llamar esto antes de iniciar una nueva sesiÃ³n
        """
        # Limpiar cola de texto
        while not self.text_queue.empty():
            try:
                self.text_queue.get_nowait()
            except:
                break
        
        # Limpiar cola de audio
        while not self.audio_queue.empty():
            try:
                self.audio_queue.get_nowait()
            except:
                break
        
        # Limpiar buffer de audio
        self.audio_buffer = []
        
        # Resetear estado de voz
        self.is_speaking = False
        self.last_sound_time = None
        
        print("ğŸ”„ SesiÃ³n de voz reseteada - Todo el historial limpiado")
    
    def start_listening(self):
        """Inicia captura de voz - LIMPIA EL HISTORIAL AUTOMÃTICAMENTE"""
        if self.is_listening:
            return
        
        # IMPORTANTE: Limpiar historial al iniciar nueva sesiÃ³n
        self.reset_session()
        
        self.is_listening = True
        
        # Thread para capturar audio
        capture_thread = Thread(target=self._capture_audio, daemon=True)
        capture_thread.start()
        
        # Thread para procesar audio
        process_thread = Thread(target=self._process_audio, daemon=True)
        process_thread.start()
        
        print("ğŸ”´ Escuchando... (SesiÃ³n nueva)")
    
    def stop_listening(self):
        """Detiene captura"""
        self.is_listening = False
        
        # Procesar audio restante si hay
        if self.audio_buffer:
            self._transcribe_buffer()
        
        print("â¹ï¸  Voz detenida")
    
    def get_all_text(self):
        """Obtiene todo el texto acumulado de la sesiÃ³n actual"""
        texts = []
        while not self.text_queue.empty():
            texts.append(self.text_queue.get())
        
        result = " ".join(texts) if texts else ""
        
        if result:
            print(f"ğŸ“‹ Texto acumulado en esta sesiÃ³n: {result}")
        else:
            print("ğŸ“‹ No hay texto en esta sesiÃ³n")
        
        return result
    
    def _audio_callback(self, indata, frames, time_info, status):
        """Callback para capturar audio del micrÃ³fono"""
        if status:
            print(f"âš ï¸  Estado: {status}")
        self.audio_queue.put(indata.copy())
    
    def _capture_audio(self):
        """Captura audio del micrÃ³fono"""
        print("âš™ï¸  Ajustando al ruido ambiente...")
        
        with sd.InputStream(
            samplerate=self.sample_rate,
            channels=self.channels,
            callback=self._audio_callback,
            blocksize=2048
        ):
            print("âœ… Listo para escuchar")
            while self.is_listening:
                sd.sleep(100)
    
    def _calculate_energy(self, audio_chunk):
        """Calcula la energÃ­a del audio para detectar voz"""
        return np.sqrt(np.mean(audio_chunk.astype(np.float32) ** 2))
    
    def _process_audio(self):
        """Procesa audio y transcribe cuando detecta silencio"""
        while self.is_listening:
            try:
                if not self.audio_queue.empty():
                    chunk = self.audio_queue.get()
                    audio_flat = chunk.flatten()
                    
                    # Calcular energÃ­a del chunk actual
                    energy = self._calculate_energy(audio_flat)
                    current_time = time.time()
                    
                    # Detectar si hay voz
                    if energy > self.silence_threshold:
                        # Hay voz
                        if not self.is_speaking:
                            self.is_speaking = True
                            print("ğŸ™ï¸  Detectado inicio de voz...")
                        
                        self.audio_buffer.append(audio_flat)
                        self.last_sound_time = current_time
                    
                    else:
                        # Silencio detectado
                        if self.is_speaking:
                            # Si estÃ¡bamos hablando, agregamos el silencio al buffer
                            self.audio_buffer.append(audio_flat)
                            
                            # Verificar si ha pasado suficiente tiempo de silencio
                            if self.last_sound_time and (current_time - self.last_sound_time) >= self.silence_duration:
                                print("â¸ï¸  Silencio detectado, transcribiendo...")
                                self._transcribe_buffer()
                                self.is_speaking = False
                                self.audio_buffer = []
                                self.last_sound_time = None
                
                else:
                    time.sleep(0.01)  # PequeÃ±a pausa si no hay audio
                    
            except Exception as e:
                print(f"âŒ Error en procesamiento: {e}")
                break
    
    def _transcribe_buffer(self):
        """Transcribe el buffer de audio acumulado"""
        if not self.audio_buffer:
            return
        
        try:
            # Concatenar todo el audio
            audio_data = np.concatenate(self.audio_buffer)
            
            # Verificar longitud mÃ­nima
            min_samples = int(self.min_audio_length * self.sample_rate)
            if len(audio_data) < min_samples:
                return
            
            # Normalizar audio
            audio_float = audio_data.astype(np.float32)
            max_val = np.max(np.abs(audio_float))
            
            if max_val > 0:
                audio_float = audio_float / max_val
            
            # Transcribir con Whisper
            result = self.model.transcribe(
                audio_float,
                language="es",
                fp16=(self.device == "cuda"),
                task="transcribe",
                without_timestamps=True
            )
            
            text = result["text"].strip()
            
            if text:
                self.text_queue.put(text)
                print(f"ğŸ“ Transcrito: {text}")
            
        except Exception as e:
            print(f"âŒ Error en transcripciÃ³n: {e}")


# Ejemplo de uso
if __name__ == "__main__":
    import time
    
    # Crear reconocedor
    recognizer = SpeechRecognizer(model_size="base")
    
    print("\n" + "="*60)
    print("PRUEBA DE MÃšLTIPLES SESIONES")
    print("="*60)
    
    # === SESIÃ“N 1 ===
    print("\nğŸ”µ SESIÃ“N 1 - Habla algo...")
    recognizer.start_listening()
    
    print("ğŸ’¡ Habla y haz pausas. Se transcribirÃ¡ automÃ¡ticamente.")
    print("ğŸ’¡ Esperando 10 segundos...")
    time.sleep(10)
    
    recognizer.stop_listening()
    text1 = recognizer.get_all_text()
    print(f"\nâœ… SESIÃ“N 1 FINALIZADA")
    print(f"ğŸ“„ Texto capturado: {text1}")
    
    # Pausa entre sesiones
    print("\nâ³ Pausa de 3 segundos...")
    time.sleep(3)
    
    # === SESIÃ“N 2 ===
    print("\nğŸŸ¢ SESIÃ“N 2 - Habla algo DIFERENTE...")
    recognizer.start_listening()  # Esto limpiarÃ¡ automÃ¡ticamente la sesiÃ³n anterior
    
    print("ğŸ’¡ Esta es una NUEVA sesiÃ³n. El texto anterior NO se acumularÃ¡.")
    print("ğŸ’¡ Esperando 10 segundos...")
    time.sleep(10)
    
    recognizer.stop_listening()
    text2 = recognizer.get_all_text()
    print(f"\nâœ… SESIÃ“N 2 FINALIZADA")
    print(f"ğŸ“„ Texto capturado: {text2}")
    
    # ComparaciÃ³n
    print("\n" + "="*60)
    print("COMPARACIÃ“N DE SESIONES")
    print("="*60)
    print(f"SesiÃ³n 1: {text1}")
    print(f"SesiÃ³n 2: {text2}")
    print(f"Â¿Son diferentes? {text1 != text2}")
    print("="*60)